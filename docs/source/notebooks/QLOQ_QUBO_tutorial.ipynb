{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLOQ (Qubit Logic on Qudits) – A Hands-On Tutorial\n",
    "\n",
    "Welcome to this Jupyter Notebook tutorial, where we explore **QLOQ** (Qubit Logic on Qudits) for linear optical quantum computing. We will break down the core concepts behind encoding multiple qubits into a single photon (qudit), demonstrate how **intra-group** gates (like CNOT and single-qubit rotations) are implemented **without** the usual success-probability issues, and show how **Ralph CZ** gates can link multiple qudit blocks.\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction to QLOQ]\n",
    "2. [Qudits & CNOT in a Single Photon]\n",
    "3. [Applying Rotations in a Qudit Group]\n",
    "4. [Building QLOQ Circuits with Perceval]\n",
    "5. [Example: Varying Group Sizes & Layers]\n",
    "6. [Summary]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1. Introduction to QLOQ\n",
    "\n",
    "**QLOQ** (Qubit Logic on Qudits) is a specialized architecture in linear optics that encodes multiple qubits **within a single photon**. Traditionally, a 2-qubit operation in linear optics involves two separate photons interfering at a beam splitter with a probabilistic success rate. However, **QLOQ** circumvents that for intra-group gates by confining both qubits to one photon’s modes.\n",
    "\n",
    "- **Inter-group** entangling gates (between different photons) still rely on a *Ralph CZ* gate, which is post-selected (probabilistic).\n",
    "- **Intra-group** gates (like CNOT, CZ, single-qubit rotations) become deterministic mode permutations and transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Qudits & CNOT in a Single Photon\n",
    "\n",
    "### Qudits\n",
    "\n",
    "A **qubit** is a 2-level system |0> or |1>. A **qudit** extends this to \\(d\\) levels. For a **2-qubit** block, \\(d = 4\\). We treat each logical basis state as a unique optical mode:\n",
    "00 → mode 0\n",
    "01 → mode 1\n",
    "10 → mode 2\n",
    "11 → mode 3\n",
    "\n",
    "\n",
    "A single photon occupying exactly one of these four modes represents any superposition of the 2-qubit space.\n",
    "\n",
    "### CNOT Within a Qudit\n",
    "\n",
    "In standard linear optics, a **CNOT** between two separate photons is probabilistic. In QLOQ, if both qubits are in the *same* photon, a CNOT is merely a **mode permutation**:\n",
    "\n",
    "- |10> ---> |11>\n",
    "- |00> and |01> remain the same\n",
    "\n",
    "Hence:\n",
    "\n",
    "| Mode Index | Binary State | CNOT Output |\n",
    "|------------|-------------|-------------|\n",
    "| 0          | 00          | 00          |\n",
    "| 1          | 01          | 01          |\n",
    "| 2          | 10          | 11          |\n",
    "| 3          | 11          | 10          |\n",
    "\n",
    "This operation is **deterministic** because it’s implemented entirely within the single photon's modes, bypassing the usual success probability constraints.\n",
    "\n",
    "> **CZ** is similarly done by a mode permutation + Hadamards on the target qubit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Applying Rotations in a Qudit Group\n",
    "\n",
    "## Applying Rotations in a Qudit Group\n",
    "\n",
    "When **multiple qubits** are encoded into a **single photon** (a qudit), each logical qubit corresponds to a specific **pairing of modes**. For a **2-qubit** group (4 modes total):\n",
    "\n",
    "- **Modes**:\n",
    "  **0 → |00⟩**,\n",
    "  **1 → |01⟩**,\n",
    "  **2 → |10⟩**,\n",
    "  **3 → |11⟩**\n",
    "\n",
    "- **Second qubit** flips between |0> and |1> in the *rightmost bit*, so to rotate it, we **pair**:\n",
    "  - (0,1) → |00>, |01>\n",
    "  - (2,3) → |10>, |11>\n",
    "\n",
    "- **First qubit** flips in the *leftmost bit*, so to rotate it, we **pair**:\n",
    "  - (0,2) → |00>, |10>\n",
    "  - (1,3) → |01>, |11>\n",
    "\n",
    "- So in practice we would apply a 2 mode parametrized beamsplitter for the specific rotation we want to achieve( Rx, Ry, Rz etc ) for each combination corresponding to the qubit we wish to act on.\n",
    "- Thankfully all this logic and all relevant swaps have been pre-coded into the ansatz builder so the user(you) need not worry too much about them.\n",
    "\n",
    "> **Key Insight**: **Intra-group operations** are “layerwise,” meaning you stack them: first apply a rotation on the second qubit via parametrized beamsplitters on the correct pairs of modes, then do some internal mode swap, then apply a rotation on the first qubit by doing similarly, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Building QLOQ Circuits with Perceval\n",
    "\n",
    "Perceval provides a **`QLOQ ansatz`** that helps you define:\n",
    "\n",
    "1. **Group Sizes**: e.g., `[Encoding.QUDIT2, Encoding.DUAL_RAIL]`\n",
    "2. **Layers**: e.g., `[\"Y\", \"X\"]` for Y then X rotations\n",
    "3. **Phases**: the numerical angles for each rotation (or `None` for symbolic)\n",
    "4. **Entangling Gate** (`ctype`): either `\"cx\"` or `\"cz\"` inside each group, plus a Ralph CZ across groups.\n",
    "\n",
    "Below is a minimal code snippet showing how to construct a QLOQ circuit (as a `Processor`) and display it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.014410300Z",
     "start_time": "2025-01-16T10:20:47.050619900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of required phases: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "<drawsvg.drawing.Drawing at 0x7f0376dadba0>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     width=\"1197.5\" height=\"656.25\" viewBox=\"-54.0 0 958.0 525.0\">\n<defs>\n</defs>\n<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M10,375.0 L25,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M27,2 L823,2 L823,498 L27,498 Z\" stroke=\"black\" fill=\"lightblue\" stroke-dasharray=\"1,2\" stroke-linejoin=\"miter\" />\n<text x=\"29\" y=\"505\" font-size=\"8\" text-anchor=\"start\">CPLX</text>\n<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,2.5 L122.5,2.5 L122.5,197.5 L27.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M125,25 L225,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,75 L225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,125 L225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,175 L225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M127.5,2.5 L222.5,2.5 L222.5,197.5 L127.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"135\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CX2</text>\n<path d=\"M225,25 L325,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,75 L325,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,125 L325,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,175 L325,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M227.5,2.5 L322.5,2.5 L322.5,197.5 L227.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"235\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,325 L125,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M25,375 L125,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M27.5,202.5 L122.5,202.5 L122.5,397.5 L27.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"35\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M125,225 L225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,275 L225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,325 L225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M125,375 L225,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M127.5,202.5 L222.5,202.5 L222.5,397.5 L127.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"135\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CX2</text>\n<path d=\"M225,225 L325,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,275 L325,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,325 L325,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M225,375 L325,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M227.5,202.5 L322.5,202.5 L322.5,397.5 L227.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"235\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M328,225 L372,425\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M325,225 L328,225 L372,425 L375,425\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M328,275 L372,475\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M325,275 L328,275 L372,475 L375,475\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M328,325 L372,225\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M325,325 L328,325 L372,225 L375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M328,375 L372,275\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M325,375 L328,375 L372,275 L375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,125.0 L375,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,175.0 L375,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,375 L475,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M377.5,102.5 L472.5,102.5 L472.5,397.5 L377.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"385\" y=\"124\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\"><tspan x=\"385\" dy=\"0em\">POSTPROCESSED</tspan><tspan x=\"385\" dy=\"1em\">CZ</tspan></text>\n<path d=\"M375,425.0 L475,425.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M375,475.0 L475,475.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,225 L522,325\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M475,225 L478,225 L522,325 L525,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,275 L522,375\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M475,275 L478,275 L522,375 L525,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,425 L522,225\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M475,425 L478,425 L522,225 L525,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M478,475 L522,275\" stroke=\"white\" stroke-width=\"6\" fill=\"none\" />\n<path d=\"M475,475 L478,475 L522,275 L525,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,25.0 L475,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M325,75.0 L475,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,25 L575,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,75 L575,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,125 L575,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M475,175 L575,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M477.5,2.5 L572.5,2.5 L572.5,197.5 L477.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"485\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M575,25 L675,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,75 L675,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,125 L675,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M575,175 L675,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M577.5,2.5 L672.5,2.5 L672.5,197.5 L577.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"585\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CX2</text>\n<path d=\"M675,25 L775,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M675,75 L775,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M675,125 L775,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M675,175 L775,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M677.5,2.5 L772.5,2.5 L772.5,197.5 L677.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"685\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M525,225 L625,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,275 L625,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,325 L625,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M525,375 L625,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M527.5,202.5 L622.5,202.5 L622.5,397.5 L527.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"535\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M625,225 L725,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,275 L725,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,325 L725,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M625,375 L725,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M627.5,202.5 L722.5,202.5 L722.5,397.5 L627.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"635\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CX2</text>\n<path d=\"M725,225 L825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M725,275 L825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M725,325 L825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M725,375 L825,375\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M727.5,202.5 L822.5,202.5 L822.5,397.5 L727.5,397.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n<text x=\"735\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">GROUPRYMULTI2</text>\n<path d=\"M775,25.0 L825,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,75.0 L825,75.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,125.0 L825,125.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M775,175.0 L825,175.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n<path d=\"M825,25.0 L840,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,75.0 L840,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,125.0 L840,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,175.0 L840,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,225.0 L840,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,275.0 L840,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,325.0 L840,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M825,375.0 L840,375.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n<path d=\"M-2,15 L10,15 L10,185 L-2,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<text x=\"-2\" y=\"191\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[Group 0]</text>\n<path d=\"M-2,215 L10,215 L10,385 L-2,385 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<text x=\"-2\" y=\"391\" font-size=\"6\" text-anchor=\"start\" font-style=\"italic\">[Group 1]</text>\n<path d=\"M7,475 C7,475,7,465,17,465 L25,465 L25,485 L17,485 C7,485,7,475,7,475 L7,475\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n<text x=\"13\" y=\"491\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n<text x=\"17\" y=\"478\" font-size=\"7\" text-anchor=\"middle\">0</text>\n<path d=\"M7,425 C7,425,7,415,17,415 L25,415 L25,435 L17,435 C7,435,7,425,7,425 L7,425\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n<text x=\"13\" y=\"441\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n<text x=\"17\" y=\"428\" font-size=\"7\" text-anchor=\"middle\">0</text>\n<path d=\"M840,15 L852,15 L852,185 L840,185 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<text x=\"852\" y=\"191\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[Group 0]</text>\n<path d=\"M840,215 L852,215 L852,385 L840,385 Z\" stroke=\"black\" fill=\"lightgray\" stroke-linejoin=\"miter\" />\n<text x=\"852\" y=\"391\" font-size=\"6\" text-anchor=\"end\" font-style=\"italic\">[Group 1]</text>\n<path d=\"M833,485 L825,485 L825,465 L833,465 C833,465,843,465,843,475 C843,485,833,485,833,485 L833,485\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n<text x=\"838\" y=\"461\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald0]</text>\n<text x=\"833\" y=\"478\" font-size=\"7\" text-anchor=\"middle\">0</text>\n<path d=\"M833,435 L825,435 L825,415 L833,415 C833,415,843,415,843,425 C843,435,833,435,833,435 L833,435\" stroke-width=\"1\" stroke=\"black\" stroke-linejoin=\"miter\" fill=\"white\" />\n<text x=\"838\" y=\"411\" font-size=\"6\" text-anchor=\"middle\" font-style=\"italic\">[herald1]</text>\n<text x=\"833\" y=\"428\" font-size=\"7\" text-anchor=\"middle\">0</text>\n<text x=\"850\" y=\"28.0\" font-size=\"10\" text-anchor=\"end\">0</text>\n<text x=\"850\" y=\"78.0\" font-size=\"10\" text-anchor=\"end\">1</text>\n<text x=\"850\" y=\"128.0\" font-size=\"10\" text-anchor=\"end\">2</text>\n<text x=\"850\" y=\"178.0\" font-size=\"10\" text-anchor=\"end\">3</text>\n<text x=\"850\" y=\"228.0\" font-size=\"10\" text-anchor=\"end\">4</text>\n<text x=\"850\" y=\"278.0\" font-size=\"10\" text-anchor=\"end\">5</text>\n<text x=\"850\" y=\"328.0\" font-size=\"10\" text-anchor=\"end\">6</text>\n<text x=\"850\" y=\"378.0\" font-size=\"10\" text-anchor=\"end\">7</text>\n<text x=\"0\" y=\"28.0\" font-size=\"10\" text-anchor=\"start\">0</text>\n<text x=\"0\" y=\"78.0\" font-size=\"10\" text-anchor=\"start\">1</text>\n<text x=\"0\" y=\"128.0\" font-size=\"10\" text-anchor=\"start\">2</text>\n<text x=\"0\" y=\"178.0\" font-size=\"10\" text-anchor=\"start\">3</text>\n<text x=\"0\" y=\"228.0\" font-size=\"10\" text-anchor=\"start\">4</text>\n<text x=\"0\" y=\"278.0\" font-size=\"10\" text-anchor=\"start\">5</text>\n<text x=\"0\" y=\"328.0\" font-size=\"10\" text-anchor=\"start\">6</text>\n<text x=\"0\" y=\"378.0\" font-size=\"10\" text-anchor=\"start\">7</text>\n</svg>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example: Building a QLOQ circuit in Perceval\n",
    "\n",
    "from perceval import pdisplay, catalog, Encoding\n",
    "from perceval import LogicalState\n",
    "\n",
    "# 1) Get the QLOQ ansatz from Perceval's catalog\n",
    "ansatz = catalog[\"QLOQ ansatz\"]\n",
    "\n",
    "# 2) Define groups of qubits (each group is a qudit)\n",
    "#    For demonstration: one 2-qubit group (QUDIT2) + one single-qubit group (DUAL_RAIL)\n",
    "group_sizes = [Encoding.QUDIT2, Encoding.QUDIT2]\n",
    "\n",
    "# 3) Choose the single-qubit layers we want (Y, X, or Z)\n",
    "layers = [\"Y\"]  # e.g., apply Y rotations in each group\n",
    "#generally Y rotations are sufficient\n",
    "\n",
    "# 4) Compute how many parameter phases are needed\n",
    "nb_phases = ansatz.get_parameter_nb(group_sizes, len(layers))\n",
    "print(\"Number of required phases:\", nb_phases)\n",
    "\n",
    "# 5) (Optional) Provide numeric phases or use None for symbolic placeholders\n",
    "phases = None  # Use symbolic parameters for visualization\n",
    "\n",
    "# 6) Build the QLOQ processor with 'ctype=\"cx\"'\n",
    "circ = ansatz.build_processor(\n",
    "    group_sizes=group_sizes,\n",
    "    layers=layers,\n",
    "    phases=phases,\n",
    "    ctype=\"cx\"\n",
    ")\n",
    "\n",
    "# 7) Display the resulting circuit\n",
    "pdisplay(circ, recursive=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ansatz in the qubit picture will then have this form where layers of 2 qubit blocks linked by a multi-controlled Z gate which takes the form of a CCCZ here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Snippet\n",
    "\n",
    "1. **Catalog & Ansatz**\n",
    "   - `catalog[\"QLOQ ansatz\"]` fetches the parametric circuit constructor for QLOQ.\n",
    "\n",
    "2. **Group Sizes**\n",
    "   - `[Encoding.QUDIT2, Encoding.DUAL_RAIL]` means we have **two** photons:\n",
    "     - Photon 1: a 2-qubit qudit (4 modes)\n",
    "     - Photon 2: a 1-qubit dual-rail encoding (2 modes)\n",
    "\n",
    "3. **Layers**\n",
    "   - `[\"Y\", \"X\"]` means each group sees a Y-rotation layer, then an X-rotation layer.\n",
    "\n",
    "4. **Phases**\n",
    "   - `ansatz.get_parameter_nb(...)` returns how many numeric angles we need. Setting `phases=None` uses symbolic placeholders.\n",
    "\n",
    "5. **`ctype=\"cx\"`**\n",
    "   - Intra-group entangling gates are CNOT-based. They can be set to 'cx' or 'cz' gates. Deterministic and accomplished via swaps.\n",
    "   - Inter-group entangling gates are accomplished via an unbalanced Ralph CZ to accomplish a CC.....CZ operation. A balanced Ralph CZ has the same success probability(1/9) for each input state. An **unbalanced** version has different success probability for each input. It was chosen because it performs empirically better than the standard CCCZ and requires less post-selected modes.\n",
    "\n",
    "6. **`pdisplay(circ, recursive=True)`**\n",
    "   - Shows the circuit structure, including the single-qubit gates and any inter-group connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.080372900Z",
     "start_time": "2025-01-16T10:21:00.035821800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of required phases: 72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#You can easily change the group sizes or rotation layers:\n",
    "import perceval as pcvl\n",
    "from perceval import catalog, Encoding\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "ansatz = catalog[\"QLOQ ansatz\"]\n",
    "\n",
    "# Suppose we have three qudit groups:\n",
    "#   2-qubit (QUDIT2), 2-qubit (QUDIT2), 1-qubit (DUAL_RAIL)\n",
    "group_sizes = [Encoding.QUDIT2, Encoding.QUDIT2, Encoding.DUAL_RAIL]\n",
    "#corresponds to 5 qubits\n",
    "\n",
    "# Let's apply 3 layers: Y, Y, X\n",
    "layers = [\"Y\", \"Y\", \"X\"]\n",
    "\n",
    "nb_phases = ansatz.get_parameter_nb(group_sizes, len(layers))\n",
    "print(\"New number of required phases:\", nb_phases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 6. Summary\n",
    "\n",
    "**QLOQ** offers a unique way to encode **multiple qubits** in **one photon** (creating qudits). The major advantage is that **CNOTs and single-qubit rotations** within that qudit can be executed deterministically without the usual success probability of two-photon gates. When linking multiple qudit blocks, **Ralph CZ** gates are used, which are **probabilistic** and post-selected.\n",
    "\n",
    "### Key Points\n",
    "- **Qudits**: 2 qubits = 4 modes in a single photon, 3 qubits = 8 modes, etc.\n",
    "- **Intra-group** gates (e.g., CNOT, Ry, Rz, Rx → Mode permutations and layers of beamsplitters.\n",
    "- **Inter-group** gates → Ralph CZ (post-selected) forming an unbalanced multi-controlled Z.\n",
    "- **Layerwise approach**: We apply rotations/cnot gates in a sequence of “layers,” possibly swapping modes to target the correct qubit.\n",
    "\n",
    "In upcoming sections, you can:\n",
    "- **Integrate** a classical optimizer (e.g., COBYLA) to do VQE-like or QAOA-like tasks on these QLOQ circuits.\n",
    "- Explore **QUBO** matrices and measure the resulting cost function from the photonic simulator.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Functions Explained\n",
    "\n",
    "These two functions, **`to_fock_state`** and **`fock_to_qubit_state`**, convert between:\n",
    "1. A **bitstring representation** of qubits (e.g., `\"0101\"`).\n",
    "2. A **Fock-state representation** (a list of occupation numbers, eventually wrapped in a `pcvl.BasicState`).\n",
    "\n",
    "### Key Idea\n",
    "- **Bitstring**: Represents qubits in the usual binary sense, e.g. `\"00\"` or `\"01\"`.\n",
    "- **Fock State**: In Perceval, a `BasicState` is a list of photon occupation numbers for each mode. A single photon occupying one of \\(2^n\\) possible modes (for an \\(n\\)-qubit group) is stored as a one-hot vector (e.g., `[0,1,0,0]` for mode 1 out of 4).\n",
    "\n",
    "These functions handle situations where **multiple groups** of qubits are each encoded in a **qudit**. For example, a group of **size=2** means 4 modes; a group of **size=3** means 8 modes, etc.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.081389800Z",
     "start_time": "2025-01-16T10:21:00.046354400Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_fock_state(qubit_state: str, group_sizes: List[int]) -> pcvl.BasicState:\n",
    "    \"\"\"\n",
    "    Convert a multi-qubit bitstring into a Perceval Fock-state representation.\n",
    "\n",
    "    Args:\n",
    "        qubit_state: e.g. \"0101\", a string of bits\n",
    "        group_sizes: each integer indicates how many qubits in that group\n",
    "                     (so each group has 2^size possible modes)\n",
    "\n",
    "    Returns:\n",
    "        pcvl.BasicState: a one-hot vector indicating the photon's occupation\n",
    "                         for each group, concatenated across groups.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    fock_state = []\n",
    "\n",
    "    for size in group_sizes:\n",
    "        # If this group has 'size' qubits, we have 2^size modes in it\n",
    "        if  size != 0:\n",
    "            group_length = 2 ** size\n",
    "            # Extract the bits for this group\n",
    "            group_qubit_state = qubit_state[offset : offset + size]\n",
    "            # Convert that bitstring to an integer index\n",
    "            state_index = int(group_qubit_state, 2)\n",
    "            # Build a one-hot vector of length group_length\n",
    "            group_fock_state = [1 if i == state_index else 0 for i in range(group_length)]\n",
    "            fock_state += group_fock_state\n",
    "            offset += size\n",
    "\n",
    "\n",
    "\n",
    "    return pcvl.BasicState(fock_state)\n",
    "\n",
    "\n",
    "def fock_to_qubit_state(fock_state: List[int], group_sizes: List[int]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Convert a Perceval Fock-state representation back to a multi-qubit bitstring.\n",
    "\n",
    "    Args:\n",
    "        fock_state: a one-hot vector for all groups (concatenated)\n",
    "        group_sizes: each integer indicates how many qubits are in that group\n",
    "\n",
    "    Returns:\n",
    "        A bitstring (e.g. \"0101\"), or None if the Fock state is invalid.\n",
    "    \"\"\"\n",
    "    # Make a local copy\n",
    "    fock_state = [i for i in fock_state]\n",
    "\n",
    "    # Expected total length = sum of (2^group_size) for each group\n",
    "    expected_length = sum([2 ** size for size in group_sizes])\n",
    "    if len(fock_state) != expected_length:\n",
    "        return None\n",
    "\n",
    "    offset = 0\n",
    "    qubit_state_binary = \"\"\n",
    "\n",
    "    for size in group_sizes:\n",
    "        group_length = 2 ** size\n",
    "        group_fock_state = fock_state[offset : offset + group_length]\n",
    "\n",
    "        # We expect exactly one '1' in the chunk (indicating the photon mode)\n",
    "        if group_fock_state.count(1) != 1:\n",
    "            return None\n",
    "\n",
    "        state_index = group_fock_state.index(1)\n",
    "        # Convert index to binary (of width 'size' bits)\n",
    "        binary_state = format(state_index, f'0{size}b')\n",
    "        qubit_state_binary += binary_state\n",
    "\n",
    "        offset += group_length\n",
    "\n",
    "    return qubit_state_binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How `to_fock_state` Works\n",
    "\n",
    "1. **Iterate** over each group in `group_sizes`.\n",
    "2. For a group of **size = n**, we have \\(2^n\\) modes.\n",
    "3. Slice `qubit_state[offset : offset + n]` to get the bits for that group.\n",
    "   - Example: If `qubit_state=\"0101\"` and the group size = 2, we might take `\"01\"`.\n",
    "4. Convert that local bitstring (`\"01\"`) to an **integer** (`int(\"01\", 2) = 1`).\n",
    "5. Build a **one-hot** vector of length \\(2^n\\), placing a `1` at that integer index.\n",
    "   - E.g. if the index is `1` and `n=2`, that’s `[0,1,0,0]`.\n",
    "6. Concatenate these one-hot vectors for **all** groups into a single list of occupation numbers.\n",
    "7. Return `pcvl.BasicState(...)` with that final list.\n",
    "\n",
    "#### Example 1\n",
    "- `qubit_state = \"0011\"`\n",
    "- `group_sizes = [2,2]`  (two groups, each 2 qubits)\n",
    "\n",
    "**Step by Step**:\n",
    "- Group A: size=2 → take `\"00\"` → `int(\"00\",2) = 0` → one-hot = `[1,0,0,0]`\n",
    "- Group B: size=2 → take `\"11\"` → `int(\"11\",2) = 3` → one-hot = `[0,0,0,1]`\n",
    "\n",
    "Final Fock state = `[1,0,0,0, 0,0,0,1]` → a single photon in mode0 of groupA **and** mode3 of groupB (concatenated).\n",
    "\n",
    "### How `fock_to_qubit_state` Works\n",
    "\n",
    "1. **Check** the total length needed: sum of \\((2^{\\text{group_size}})\\).\n",
    "2. **Slice** each group’s chunk out of the big `fock_state`.\n",
    "3. Within that chunk, ensure exactly **one** entry is `1`.\n",
    "4. The **index** of that `1` is the integer representation of the bits for that group.\n",
    "   - Convert that index to a binary string of width `n`.\n",
    "5. Append all these binary substrings together, forming the **full** qubit bitstring.\n",
    "\n",
    "#### Example 2\n",
    "- `fock_state = [1,0,0,0, 0,0,0,1]` (length=8)\n",
    "- `group_sizes = [2,2]`\n",
    "\n",
    "**Step by Step**:\n",
    "- Group A chunk: `[1,0,0,0]` → exactly one ‘1’ at index=0 → binary of `0` with width=2 → `\"00\"`\n",
    "- Group B chunk: `[0,0,0,1]` → index=3 → binary= `\"11\"`\n",
    "\n",
    "Concatenate = `\"00\" + \"11\"` = `\"0011\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## Edge Cases\n",
    "\n",
    "\n",
    "\n",
    "1**Invalid Fock State**\n",
    "   If a chunk has more than one `1` or none at all, `fock_to_qubit_state` returns `None`. This ensures we only accept states with exactly **one** photon per group. Thus, we have post-selected\n",
    "\n",
    "2**Bitstring Offsets**\n",
    "   The variable `offset` keeps track of how many bits we’ve already consumed from `qubit_state`. This ensures we map each portion of the bitstring to its corresponding qudit group.\n",
    "\n",
    "---\n",
    "\n",
    "By using these helper functions:\n",
    "- **`to_fock_state`**: you can feed a **bitstring** into a Perceval circuit as the **initial Fock-state input**.\n",
    "- **`fock_to_qubit_state`**: you can interpret the circuit’s **measurement results** (a one-hot outcome) back into a **bitstring** for classical post-processing or optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUBO Example with a Simple QLOQ ansatz Circuit (CVaR-VQE Approach)\n",
    "\n",
    "In this notebook, we demonstrate how to tackle a **QUBO** (Quadratic Unconstrained Binary Optimization) problem using a **CVar-VQE** style approach in Perceval. This can also be verified with the other more photonic QUBO approach which uses the same QUBO matrix. We’ll show:\n",
    "\n",
    "1. **How to frame a QUBO problem** and represent it as a matrix  H .\n",
    "2. **Building a simple QLOQ circuit** (e.g., with Ry layers) to produce a variational ansatz.\n",
    "3. **Sampling** from the circuit to get a distribution of bitstrings.\n",
    "4. **Computing CVaR** to measure the cost (objective function) and performing classical optimization (COBYLA).\n",
    "5. **Identifying the best bitstring** based on the final solution.\n",
    "6. **Optional**: Plotting the final probability distribution as a histogram for visual insight.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is CVaR-VQE?\n",
    "\n",
    "**CVaR-VQE** (Conditional Value-at-Risk Variational Quantum Eigensolver) is a hybrid quantum-classical optimization technique that **goes beyond** the usual average-cost minimization seen in standard VQE:\n",
    "\n",
    "1. **VQE Recap**\n",
    "   - In a typical VQE, you prepare a **parametrized quantum circuit** (ansatz).\n",
    "   - You **sample** from it to estimate the **average** energy (or cost).\n",
    "   - A **classical optimizer** tunes the circuit parameters to **minimize** this average cost.\n",
    "\n",
    "2. **Why CVaR?**\n",
    "   - In many problems, you don’t just care about the **average** cost. You also want to avoid **worst-case** outcomes.\n",
    "   - **CVaR** (Conditional Value-at-Risk) focuses on the **worst alpha-fraction** of possible outcomes in your distribution.\n",
    "   - Practically, we *sort* outcomes by cost and *average* the top alpha portion (highest costs). If alpha is 0.5, that means we look at the top 50% of the distribution by cost. By **minimizing** that portion, we make sure the algorithm consistently avoids very high-cost states.\n",
    "\n",
    "3. **Combining CVaR with VQE**\n",
    "   - We still build a **variational circuit** and measure its outputs, but instead of updating parameters to reduce the simple average cost, we **focus on the worst tail**.\n",
    "   - This ensures the final circuit is **less likely** to produce very bad solutions.\n",
    "\n",
    "In short, **CVaR-VQE** aims to push the distribution of measured bitstrings toward reliably low-cost outcomes, rather than just optimizing the mean. This can be extremely useful for **QUBO** (Quadratic Unconstrained Binary Optimization) problems, where you want to avoid sampling high-cost bitstrings even occasionally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.113936400Z",
     "start_time": "2025-01-16T10:21:00.063341Z"
    }
   },
   "outputs": [],
   "source": [
    "import perceval as pcvl\n",
    "from perceval import catalog, Encoding\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.204001300Z",
     "start_time": "2025-01-16T10:21:00.115961500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_cvar(probabilities: List[float], values: List[float], alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Conditional Value at Risk (CVaR).\n",
    "    Given a list of probabilities and corresponding values (costs),\n",
    "    we take the worst alpha portion of outcomes and average them\n",
    "    weighted by their probabilities.\n",
    "    \"\"\"\n",
    "    sorted_indices = np.argsort(values)  # sort by ascending value\n",
    "    probs = np.array(probabilities)[sorted_indices]\n",
    "    vals = np.array(values)[sorted_indices]\n",
    "    cvar = 0\n",
    "    total_prob = 0\n",
    "\n",
    "    for p, v in zip(probs, vals):\n",
    "        if p >= alpha - total_prob:\n",
    "            p = alpha - total_prob\n",
    "        total_prob += p\n",
    "        cvar += p * v\n",
    "\n",
    "    return cvar / total_prob\n",
    "\n",
    "def expectation_value(vec_state: np.ndarray, qubo_matrix: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the expectation value for a given state with respect to a QUBO matrix.\n",
    "    Here, vec_state is a binary vector (e.g., [0,1,0,1]) converted to float,\n",
    "    and qubo_matrix is the NxN matrix of the QUBO.\n",
    "    \"\"\"\n",
    "    return np.dot(vec_state.conjugate(), np.dot(qubo_matrix, vec_state))\n",
    "\n",
    "def extract_probability_distribution(job_results: Dict, group_sizes: List[int]) -> Tuple[Dict[str, float], int]:\n",
    "    \"\"\"\n",
    "    Extract probability distribution from sampling results.\n",
    "    Returns:\n",
    "      output_dict = {bitstring: probability}\n",
    "      sum_valid_outputs = sum of all valid counts (used for normalization)\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    sum_valid_outputs = 0\n",
    "\n",
    "    # First pass: count how many valid outputs (bitstrings)\n",
    "    for res in job_results['results']:\n",
    "        qb_state = fock_to_qubit_state(res, group_sizes)\n",
    "        if qb_state:\n",
    "            sum_valid_outputs += job_results['results'][res]\n",
    "\n",
    "    # Second pass: compute probabilities for each valid bitstring\n",
    "    for res in job_results['results']:\n",
    "        qb_state = fock_to_qubit_state(res, group_sizes)\n",
    "        if qb_state:\n",
    "            output_dict[qb_state] = job_results['results'][res] / sum_valid_outputs\n",
    "\n",
    "    return output_dict, sum_valid_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:00.205001500Z",
     "start_time": "2025-01-16T10:21:00.129756500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_circuit(phases: List[float], group_sizes: List[int], layers: List[str]) -> pcvl.Circuit:\n",
    "    \"\"\"\n",
    "    Build the quantum circuit (QLOQ ansatz) with specified phases.\n",
    "   \n",
    "    \"\"\"\n",
    "    ansatz = catalog[\"QLOQ ansatz\"]\n",
    "#    group_sizes_p = [Encoding.QUDIT2 for _ in group_sizes]\n",
    "\n",
    "    #group_sizes_p = [eval(f\"Encoding.QUDIT{x}\") for x in group_sizes]\n",
    "    group_sizes_p = [Encoding.DUAL_RAIL if x == 1 else eval(f\"Encoding.QUDIT{x}\") for x in group_sizes]\n",
    "    # Method 1\n",
    "    \n",
    "   # group_sizes_p = [Encoding.QUDIT2 for _ in group_sizes]\n",
    "\n",
    "    proc = ansatz.build_processor(\n",
    "        group_sizes=group_sizes_p,\n",
    "        layers=layers,\n",
    "        phases=phases,\n",
    "        ctype=\"cz\" #can be cx too\n",
    "    )\n",
    "    return proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:44.852784900Z",
     "start_time": "2025-01-16T10:21:44.832182700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_objective_function(qubo_matrix: np.ndarray,\n",
    "                              input_state: str,\n",
    "                              group_sizes: List[int],\n",
    "                              layers: List[str],\n",
    "                              sampling_size: int,\n",
    "                              alpha: float):\n",
    "    \"\"\"\n",
    "    Create the CVaR-VQE objective function for optimization.\n",
    "    - qubo_matrix: the QUBO cost matrix\n",
    "    - input_state: initial computational basis string (e.g. \"000000\")\n",
    "    - group_sizes: list of integers, each representing # of qubits in that group\n",
    "    - layers: e.g. [\"Y\"] or [\"Y\",\"X\"]\n",
    "    - sampling_size: how many shots to gather per evaluation\n",
    "    - alpha: the fraction for CVaR computation\n",
    "\n",
    "    Returns:\n",
    "      objective_function (callable): to be passed into an optimizer\n",
    "      best_result (list reference): to track the best (lowest) loss + best bitstring\n",
    "    \"\"\"\n",
    "    best_result = [None]  # store (loss, bitstring)\n",
    "    iteration = [0]       # track iteration count\n",
    "\n",
    "    def objective_function(phases: np.ndarray) -> float:\n",
    "        # Ensure phases are in [0, 2π]\n",
    "        phases_mod = np.mod(phases, 2 * np.pi)\n",
    "\n",
    "        # Build circuit (processor)\n",
    "        circ = build_circuit(phases_mod.tolist(), group_sizes, layers)\n",
    "\n",
    "        # Prepare input state as a Fock state\n",
    "      #  \"000000\",[2,2,2]\n",
    "      #  circ.with_input(to_fock_state(input_state, group_sizes))\n",
    "        circ.with_input(LogicalState(list(map(int, input_state))))\n",
    "\n",
    "        # Sample from the circuit\n",
    "        sampler = pcvl.algorithm.Sampler(circ, max_shots_per_call=sampling_size)\n",
    "        job = sampler.sample_count\n",
    "        job_results = job.execute_sync(sampling_size)\n",
    "\n",
    "        # Extract distribution\n",
    "        output_dict, _ = extract_probability_distribution(job_results, group_sizes)\n",
    "        if not output_dict:\n",
    "            return float('inf')  # if no valid results, large penalty\n",
    "\n",
    "        # Convert bitstrings to vectors => compute QUBO cost => gather CVaR\n",
    "        probabilities = list(output_dict.values())\n",
    "        values = [expectation_value(np.array(list(state)).astype(int), qubo_matrix)\n",
    "                  for state in output_dict.keys()]\n",
    "\n",
    "        loss = compute_cvar(probabilities, values, alpha)\n",
    "\n",
    "        # Track the best result\n",
    "        bitstring = max(output_dict, key=output_dict.get)\n",
    "        if best_result[0] is None or loss < best_result[0][0]:\n",
    "            best_result[0] = (loss, bitstring)\n",
    "\n",
    "        iteration[0] += 1\n",
    "        print(f\"Iteration {iteration[0]}: Loss = {loss}, Best bitstring = {bitstring}\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return objective_function, best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:45.918288800Z",
     "start_time": "2025-01-16T10:21:45.868770600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimize_qubo(qubo_matrix: np.ndarray,\n",
    "                  input_state: str,\n",
    "                  group_sizes: List[int],\n",
    "                  layers: List[str],\n",
    "                  sampling_size: int = 100000,\n",
    "                  alpha: float = 0.5,\n",
    "                  maxiter: int = 50) -> Tuple[float, str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run the optimization using COBYLA to find phases that minimize CVaR for the given QUBO problem.\n",
    "    - qubo_matrix: your QUBO cost matrix\n",
    "    - input_state: initial bitstring\n",
    "    - group_sizes: e.g. [2,2,2]\n",
    "    - layers: e.g. [\"Y\"]\n",
    "    - sampling_size: how many shots per circuit evaluation\n",
    "    - alpha: fraction for CVaR\n",
    "    - maxiter: max COBYLA iterations\n",
    "\n",
    "    Returns:\n",
    "      final_loss (float): best CVaR found\n",
    "      best_bitstring (str): best measured bitstring\n",
    "      optimal_phases (np.ndarray): the phase vector that achieved the best result\n",
    "    \"\"\"\n",
    "    ansatz = catalog[\"QLOQ ansatz\"]\n",
    " \n",
    "    group_sizes_p = [Encoding.DUAL_RAIL if x == 1 else eval(f\"Encoding.QUDIT{x}\") for x in group_sizes]\n",
    "    nb_phases = ansatz.get_parameter_nb(group_sizes_p, len(layers))\n",
    "\n",
    "    # Random initial guess for the phases\n",
    "    initial_phases = np.random.uniform(0, 2*np.pi, nb_phases)\n",
    "\n",
    "    # Build the objective function\n",
    "    objective_function, best_result = create_objective_function(\n",
    "        qubo_matrix, input_state, group_sizes, layers, sampling_size, alpha\n",
    "    )\n",
    "\n",
    "    # Define a custom inequality to keep phases in [0, 2π] if we want\n",
    "    def constraints(x):\n",
    "        return np.min(np.array([2 * np.pi - x, x]))\n",
    "\n",
    "    # Minimize\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_phases,\n",
    "        method='cobyla',\n",
    "        #constraints={'type': 'ineq', 'fun': constraints},\n",
    "        options={\n",
    "            'maxiter': maxiter,\n",
    "         #   'rhobeg': 0.1,\n",
    "         #   'rhoend': 1e-6\n",
    "        }\n",
    "    )\n",
    "\n",
    "    best_loss = result.fun\n",
    "    best_bitstring = best_result[0][1]\n",
    "    return best_loss, best_bitstring, result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:21:46.962000500Z",
     "start_time": "2025-01-16T10:21:46.885776100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict\n",
    "\n",
    "def plot_bitstring_distribution(prob_dict: Dict[str, float], top_n: int = 10, title: str = \"Top Bitstring Probabilities\"):\n",
    "    \"\"\"\n",
    "    Plot a histogram of the top N most probable bitstrings.\n",
    "\n",
    "    Args:\n",
    "        prob_dict: e.g. {\"000000\": 0.25, \"100100\": 0.15, ...}\n",
    "        top_n: how many top states to display\n",
    "        title: plot title\n",
    "    \"\"\"\n",
    "    # Convert dict to list of (bitstring, probability) pairs\n",
    "    items = list(prob_dict.items())\n",
    "\n",
    "    # Sort descending by probability\n",
    "    items.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Take the top 'top_n' states\n",
    "    items = items[:top_n]\n",
    "\n",
    "    # Unzip into two lists\n",
    "    bitstrings, probs = zip(*items)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(bitstrings, probs, color='darkviolet')\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(\"Bitstring\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Putting It All Together\n",
    "\n",
    "Below is a complete **example** usage, showing how to:\n",
    "\n",
    "1. Define a sample QUBO matrix (6-qubit problem).\n",
    "2. Optimize using Ry layers in a QLOQ circuit.\n",
    "3. Print the final result and best bitstring.\n",
    "4. Optionally, sample the final circuit once more to plot the output distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T10:22:20.294029700Z",
     "start_time": "2025-01-16T10:21:48.151233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss = -1.8786533333333344, Best bitstring = 000011\n",
      "Iteration 2: Loss = -4.795973333333333, Best bitstring = 001011\n",
      "Iteration 3: Loss = -12.376706666666667, Best bitstring = 000011\n",
      "Iteration 4: Loss = -8.182566666666666, Best bitstring = 001011\n",
      "Iteration 5: Loss = -6.623506666666667, Best bitstring = 000011\n",
      "Iteration 6: Loss = -21.015766666666668, Best bitstring = 011011\n",
      "Iteration 7: Loss = -21.27556, Best bitstring = 011011\n",
      "Iteration 8: Loss = -14.879753333333337, Best bitstring = 011000\n",
      "Iteration 9: Loss = -21.044606666666667, Best bitstring = 011011\n",
      "Iteration 10: Loss = -21.501546666666666, Best bitstring = 011101\n",
      "Iteration 11: Loss = -21.454886666666667, Best bitstring = 011011\n",
      "Iteration 12: Loss = -21.475546666666666, Best bitstring = 011011\n",
      "Iteration 13: Loss = -21.216193333333333, Best bitstring = 011011\n",
      "Iteration 14: Loss = -7.7659333333333365, Best bitstring = 111101\n",
      "Iteration 15: Loss = -17.53072666666667, Best bitstring = 011101\n",
      "Iteration 16: Loss = -18.069020000000002, Best bitstring = 010101\n",
      "Iteration 17: Loss = -1.465046666666669, Best bitstring = 111101\n",
      "Iteration 18: Loss = -17.90388666666667, Best bitstring = 011101\n",
      "Iteration 19: Loss = -16.169220000000003, Best bitstring = 010101\n",
      "Iteration 20: Loss = -21.294553333333337, Best bitstring = 011011\n",
      "Iteration 21: Loss = -21.32036666666667, Best bitstring = 011011\n",
      "Iteration 22: Loss = -21.220233333333333, Best bitstring = 011011\n",
      "Iteration 23: Loss = -8.077960000000003, Best bitstring = 011111\n",
      "Iteration 24: Loss = -19.130160000000004, Best bitstring = 011101\n",
      "Iteration 25: Loss = -19.33216666666667, Best bitstring = 011100\n",
      "Iteration 26: Loss = -21.31114, Best bitstring = 011011\n",
      "Iteration 27: Loss = -21.44467333333333, Best bitstring = 011101\n",
      "Iteration 28: Loss = -21.323073333333333, Best bitstring = 011011\n",
      "Iteration 29: Loss = -21.39388, Best bitstring = 011011\n",
      "Iteration 30: Loss = -21.362233333333332, Best bitstring = 011101\n",
      "Iteration 31: Loss = -21.343153333333333, Best bitstring = 011011\n",
      "Iteration 32: Loss = -21.34389333333333, Best bitstring = 011101\n",
      "Iteration 33: Loss = -21.365266666666667, Best bitstring = 011101\n",
      "Iteration 34: Loss = -21.698666666666668, Best bitstring = 011101\n",
      "Iteration 35: Loss = -21.57222, Best bitstring = 011011\n",
      "Iteration 36: Loss = -21.69584, Best bitstring = 011101\n",
      "Iteration 37: Loss = -22.183366666666668, Best bitstring = 011011\n",
      "Iteration 38: Loss = -21.935386666666666, Best bitstring = 011011\n",
      "Iteration 39: Loss = -16.127966666666673, Best bitstring = 011111\n",
      "Iteration 40: Loss = -22.486993333333334, Best bitstring = 011011\n",
      "Iteration 41: Loss = -23.385926666666666, Best bitstring = 010011\n",
      "Iteration 42: Loss = -23.079413333333335, Best bitstring = 011011\n",
      "Iteration 43: Loss = -24.133606666666665, Best bitstring = 010111\n",
      "Iteration 44: Loss = -19.728759999999998, Best bitstring = 010011\n",
      "Iteration 45: Loss = -26.19808666666667, Best bitstring = 010110\n",
      "Iteration 46: Loss = -26.464666666666666, Best bitstring = 010110\n",
      "Iteration 47: Loss = -26.36230666666667, Best bitstring = 010110\n",
      "Iteration 48: Loss = -26.727059999999998, Best bitstring = 010110\n",
      "Iteration 49: Loss = -26.599086666666665, Best bitstring = 010110\n",
      "Iteration 50: Loss = -26.594446666666666, Best bitstring = 010110\n",
      "Iteration 51: Loss = -26.56060666666667, Best bitstring = 010110\n",
      "Iteration 52: Loss = -26.477919999999997, Best bitstring = 010110\n",
      "Iteration 53: Loss = -27.00144, Best bitstring = 010110\n",
      "Iteration 54: Loss = -27.003166666666665, Best bitstring = 010110\n",
      "Iteration 55: Loss = -27.00510666666667, Best bitstring = 010001\n",
      "Iteration 56: Loss = -27.00305333333334, Best bitstring = 010001\n",
      "Iteration 57: Loss = -27.0089, Best bitstring = 010001\n",
      "Iteration 58: Loss = -27.009179999999997, Best bitstring = 010001\n",
      "Iteration 59: Loss = -27.002373333333335, Best bitstring = 010010\n",
      "Iteration 60: Loss = -27.005639999999996, Best bitstring = 010001\n",
      "Iteration 61: Loss = -27.006200000000003, Best bitstring = 010010\n",
      "Iteration 62: Loss = -27.00682, Best bitstring = 010001\n",
      "Iteration 63: Loss = -26.995886666666667, Best bitstring = 010001\n",
      "Iteration 64: Loss = -26.834819999999997, Best bitstring = 010010\n",
      "Iteration 65: Loss = -27.006606666666666, Best bitstring = 010001\n",
      "Iteration 66: Loss = -27.021686666666668, Best bitstring = 010010\n",
      "Iteration 67: Loss = -27.055593333333334, Best bitstring = 010010\n",
      "Iteration 68: Loss = -27.069346666666668, Best bitstring = 010010\n",
      "Iteration 69: Loss = -27.08114666666667, Best bitstring = 010001\n",
      "Iteration 70: Loss = -27.058439999999997, Best bitstring = 010001\n",
      "Iteration 71: Loss = -27.06003333333333, Best bitstring = 010001\n",
      "Iteration 72: Loss = -27.098000000000003, Best bitstring = 010001\n",
      "Iteration 73: Loss = -27.17, Best bitstring = 010010\n",
      "Iteration 74: Loss = -27.155733333333334, Best bitstring = 010001\n",
      "Iteration 75: Loss = -27.24738, Best bitstring = 010001\n",
      "Iteration 76: Loss = -27.23176, Best bitstring = 010001\n",
      "Iteration 77: Loss = -27.242213333333332, Best bitstring = 010001\n",
      "Iteration 78: Loss = -27.264706666666665, Best bitstring = 010001\n",
      "Iteration 79: Loss = -27.261786666666666, Best bitstring = 010100\n",
      "Iteration 80: Loss = -27.230446666666666, Best bitstring = 010010\n",
      "Iteration 81: Loss = -27.548479999999998, Best bitstring = 010100\n",
      "Iteration 82: Loss = -27.598539999999996, Best bitstring = 010100\n",
      "Iteration 83: Loss = -27.575826666666675, Best bitstring = 010100\n",
      "Iteration 84: Loss = -26.833759999999998, Best bitstring = 010100\n",
      "Iteration 85: Loss = -27.513360000000002, Best bitstring = 010100\n",
      "Iteration 86: Loss = -27.928006666666665, Best bitstring = 010100\n",
      "Iteration 87: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 88: Loss = -28.000000000000004, Best bitstring = 100100\n",
      "Iteration 89: Loss = -27.994633333333333, Best bitstring = 010100\n",
      "Iteration 90: Loss = -28.000000000000004, Best bitstring = 100100\n",
      "Iteration 91: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 92: Loss = -28.000000000000004, Best bitstring = 100100\n",
      "Iteration 93: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 94: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 95: Loss = -27.97765333333334, Best bitstring = 010100\n",
      "Iteration 96: Loss = -27.778653333333335, Best bitstring = 010100\n",
      "Iteration 97: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 98: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 99: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 100: Loss = -27.779553333333336, Best bitstring = 010100\n",
      "Iteration 101: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 102: Loss = -27.868146666666664, Best bitstring = 010011\n",
      "Iteration 103: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 104: Loss = -27.872046666666666, Best bitstring = 010100\n",
      "Iteration 105: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 106: Loss = -27.78544, Best bitstring = 010011\n",
      "Iteration 107: Loss = -28.000000000000004, Best bitstring = 100100\n",
      "Iteration 108: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 109: Loss = -27.99077333333333, Best bitstring = 010100\n",
      "Iteration 110: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 111: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 112: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 113: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 114: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 115: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 116: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 117: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 118: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 119: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 120: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 121: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 122: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 123: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 124: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 125: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 126: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 127: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 128: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 129: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 130: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 131: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 132: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 133: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 134: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 135: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 136: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 137: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 138: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 139: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 140: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 141: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 142: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 143: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 144: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 145: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 146: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 147: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 148: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 149: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 150: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 151: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 152: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 153: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 154: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 155: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 156: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 157: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 158: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 159: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 160: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 161: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 162: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 163: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 164: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 165: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 166: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 167: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 168: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 169: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 170: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 171: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 172: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 173: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 174: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 175: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 176: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 177: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 178: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 179: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 180: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 181: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 182: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 183: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 184: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 185: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 186: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 187: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 188: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 189: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 190: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 191: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 192: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 193: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 194: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 195: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 196: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 197: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 198: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 199: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 200: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 201: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 202: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 203: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 204: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 205: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 206: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 207: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 208: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 209: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 210: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 211: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 212: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 213: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "Iteration 214: Loss = -28.000000000000004, Best bitstring = 010100\n",
      "\n",
      "=== Final Optimization Results ===\n",
      "Final CVaR Loss: -28.000000000000004\n",
      "Best Bitstring: 010100\n",
      "Optimal Phases: [ 2.84168518  3.05904481  1.95145422  3.75374182  4.80923419  5.74609964\n",
      "  1.87237459  1.551748    5.1333966   1.58529839  4.98708443  2.44226225\n",
      "  0.88680459  3.89562565  2.50292999  0.35538349  4.26744229  5.57315565\n",
      "  3.67449095 -0.34797979  4.27973003  3.72838547  0.73559019  5.87445827]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example QUBO matrix (6-qubit)\n",
    "    H1 = np.array([\n",
    "        [2.,   32., -32., -32.,  32.,   0.],\n",
    "        [0.,    1.,  32.,   0., -32., -32.],\n",
    "        [0.,    0.,  35.,  32., -64., -32.],\n",
    "        [0.,    0.,   0.,   2., -32.,  32.],\n",
    "        [0.,    0.,   0.,   0.,  35.,  32.],\n",
    "        [0.,    0.,   0.,   0.,   0.,   4.]\n",
    "    ])\n",
    "\n",
    "    # We'll group the 6 qubits into 2 groups of 3 qubits each: [3,3], [2,2,2], [5,1], [4,2], [3,1,1] etc\n",
    "    # different group combinations may have different alpha value or sample number needs so play around with different hyperparameters\n",
    "    group_sizes = [3,3]\n",
    "\n",
    "    # Single rotation layer: [\"Y\"]\n",
    "    layers = [\"Y\"]\n",
    "\n",
    "    # Run the optimization\n",
    "    final_loss, best_bitstring, optimal_phases = optimize_qubo(\n",
    "        qubo_matrix=H1,\n",
    "        input_state=\"000000\",     # e.g. 6-qubit input in |000000>\n",
    "        group_sizes=group_sizes,\n",
    "        layers=layers,\n",
    "        sampling_size=1000000,    # how many shots for sampling\n",
    "        alpha=0.15,                # CVaR parameter\n",
    "        maxiter=400               # COBYLA iterations\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Final Optimization Results ===\")\n",
    "    print(f\"Final CVaR Loss: {final_loss}\")\n",
    "    print(f\"Best Bitstring: {best_bitstring}\")\n",
    "    print(f\"Optimal Phases: {optimal_phases}\")\n",
    "\n",
    "    # OPTIONAL: Sample final circuit with the found phases, then plot the output distribution\n",
    "    circ = build_circuit(list(optimal_phases), group_sizes, layers)\n",
    "    circ.with_input(to_fock_state(\"000000\", group_sizes))\n",
    "    sampler = pcvl.algorithm.Sampler(circ, max_shots_per_call=100000)\n",
    "    job = sampler.sample_count\n",
    "    job_results = job.execute_sync(100000)\n",
    "\n",
    "    output_dict, _ = extract_probability_distribution(job_results, group_sizes)\n",
    "    plot_bitstring_distribution(output_dict, title=\"Final Distribution After Optimization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1. **`optimize_qubo`** calls our **objective function** repeatedly, adjusting phases to reduce the **CVaR** of the QUBO cost.\n",
    "2. **`alpha`** in **CVaR** picks how much “worst tail” of outcomes we average over. alpha = 0.5 is a middle ground.\n",
    "3. **`best_bitstring`** is chosen from the final distribution’s highest-probability outcome (in practice, you might also check the distribution).\n",
    "4. The **plot** helps visualize which bitstrings are being sampled at the end of optimization.\n",
    "\n",
    "---\n",
    "\n",
    "With this approach, you have a working **CVaR-VQE** routine for **QUBO** problems using an ansatz in the **QLOQ** framework. You can expand this by:\n",
    "- Increasing the number of **layers** (e.g., `[\"Y\",\"Y\"]`).\n",
    "- Using **CX** gates instead of CZ inside groups (`ctype=\"cx\"`).\n",
    "- Changing **group_sizes** or QUBO matrix to match your real problem.\n",
    "- Exploring advanced optimization methods or different cost functions beyond QUBO.\n",
    "\n",
    "This completes our demonstration of a **QUBO** problem solved by a **CVar-VQE**-like approach in **Perceval’s QLOQ** environment. QLOQ can be applied to various problems involving a variational circuit so it is recommended to refactor this example to your needs whether by changing the loss function to match your given problem or the circuit structure itself.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T14:04:47.743702400Z",
     "start_time": "2025-01-15T14:04:47.713447100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.2.post45+2025.1.13'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcvl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
