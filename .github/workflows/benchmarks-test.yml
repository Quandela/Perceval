#this workflow run benchmarks

name: Benchmarks

on:
  workflow_dispatch:
    inputs:
      os:
        description: 'choose OS'
        required: true
        default: 'Ubuntu'
        type: choice
        options:
          - ubuntu
          - windows
      save:
        description: 'save log'
        default: false
        required: false
        type: boolean

env:
  PYTHON_V: '3.10'

jobs:
  benchmark:
    name: Run pytest-benchmark benchmark example
    runs-on: ${{ github.event.inputs.os }}-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - uses: actions/setup-python@v2
        with:
          python-version: ${{env.PYTHON_V}}

      - name: Install dependencies
        run: |
            python -m pip install --upgrade pip
            python -m pip install pytest pytest-benchmark
            python -m pip install .

#      - name: Get Previous tag version
#        id: previoustag
#        uses: "WyriHaximus/github-action-get-previous-tag@v1"
#        with:
#          fallback: 1.0.0

      - name: Initialize config
        id: variable
        run: |
          echo "tag_version=$( git describe --tags )" >> $GITHUB_ENV
          echo "folder_env=${{runner.os}}-CPython-${{env.PYTHON_V}}-64bit" >> $GITHUB_ENV
          echo "file_json=.benchmarks/${{runner.os}}-CPython-${{env.PYTHON_V}}-64bit/$( git describe --tags )_${{  github.ref_name }}_${{  github.sha }}.json" >> $GITHUB_ENV
#          echo ::set-output name=FOLDER_BENCH::.benchmarks/${{runner.os}}-CPython-${{env.PYTHON_V}}-64bit
#          echo ::set-output name=FILE_JSON::.benchmarks/${{runner.os}}-CPython-${{env.PYTHON_V}}-64bit/${{ steps.previoustag.outputs.tag }}_${{  github.ref_name }}_${{  github.sha }}.json
        shell: Bash

      - name: Run benchmark
        run: |
          pytest --benchmark-storage file://./.benchmarks/${{ env.folder_env }}
          pytest benchmark/benchmark_stepper.py --benchmark-json ${{ env.file_json }} >> pytest_result_${{ env.folder_env }}_${{ env.tag_version }}
      


      - name: store result on gh-page branch
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Python Benchmark with pytest-benchmark
          tool: 'pytest'
          output-file-path: ${{ env.file_json }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.event.inputs.save }}
          alert-threshold: '10%'
          # comment-on-alert: true
          fail-on-alert: ${{ github.event.inputs.save }}

      - name: Save benchmark report in current branch
        if: ${{ github.event.inputs.save == true }}
        run: |
          git config --global user.name 'test'
          git config --global user.email 'test@users.noreply.github.com'
          git add ${{ env.file_json }}
          git commit -am "Automated benchmark report"
          git push

      # upload the result on action git
      - name: upload the result
        uses: actions/upload-artifact@v3
        with:
          name: pytest_log
          path: |
            pytest_result_${{ env.folder_env }}_${{ env.tag_version }}
            ${{ env.file_json }}
      - name: Download the result on github action
        uses: actions/download-artifact@v3
        with:
          name: pytest_log
