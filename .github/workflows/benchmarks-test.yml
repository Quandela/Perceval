#this is a manual workflow that runs benchmarks at benchmarks/benchmark_*.py
# file name .benchmarks/<runner>_CPython-<PyVersion>/<tagVersion>_<branches>_<workflowNB>_<commit>.json
# compare the logs with the same runner and the same version of python
# upload the artifact to the github action
# save the log on the gh-page branch (benchmarks/<runner>_CPython-<PyVersion>/data)
# push on the current branch

name: Benchmarks

on:
  workflow_dispatch:
    inputs:
      os:
        description: 'Choose OS'
        required: true
        default: 'MiniMac_arm64'
        type: choice
        options:
          - MiniMac_arm64
          - ubuntu-latest
      save:
        description: 'Save log'
        default: false
        required: false
        type: boolean
#      python_v:
#        description: 'python version'
#        required: true
#        default: '3.10'
#        type: choice
#        options:
#          - '3.10'
#          - '3.9'
#          - '3.8'

env:
  python_v: '3.9'

jobs:
  benchmark:
    name: Run pytest-benchmark benchmark example
    runs-on: ${{ github.event.inputs.os }}
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      # install python, already DL on MiniMac_arm64
      - if:  ${{ github.event.inputs.os != 'MiniMac_arm64' }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ env.python_v }}

      - name: Install dependencies
        run: |
            python -m pip install --upgrade pip
            python -m pip install pytest pytest-benchmark
            python -m pip install .

      # save var env use bash shell for notLinux
      - if: runner.os == 'Linux'
        name: Initialize config linux
        run: |
          echo "tag_version=$( git describe --tags )" >> $GITHUB_ENV
          echo "folder_env=${{ github.event.inputs.os }}-CPython-${{ env.python_v }}" >> $GITHUB_ENV
          echo "file_json=.benchmarks/${{ github.event.inputs.os }}-CPython-${{ env.python_v }}/$( git describe --tags )_${{ github.ref_name }}_${{ github.run_attempt }}_${{ github.sha }}.json" >> $GITHUB_ENV

      - if: runner.os != 'Linux'
        name: Initialize config notLinux
        run: |
          echo "tag_version=$( git describe --tags )" >> $GITHUB_ENV
          echo "folder_env=${{ github.event.inputs.os }}-CPython-${{ env.python_v }}" >> $GITHUB_ENV
          echo "file_json=.benchmarks/${{ github.event.inputs.os }}-CPython-${{ env.python_v }}/$( git describe --tags )_${{ github.ref_name }}_${{ github.run_attempt }}_${{ github.sha }}.json" >> $GITHUB_ENV
        shell: Bash


      - name: Run benchmark
        run: |
          python -m pytest --benchmark-storage file://./.benchmarks/${{ env.folder_env }}
          python -m pytest benchmark/benchmark_*.py --benchmark-json ${{ env.file_json }} >> pytest_result_${{ env.folder_env }}_${{ env.tag_version }}
      - name: compare benchmark
        run: |
          pytest-benchmark compare .benchmarks/${{ env.folder_env }}/* >> compare_result_${{ env.folder_env }}_${{ env.tag_version }}

      # upload the result on action git
      - name: upload the result
        uses: actions/upload-artifact@v3
        with:
          name: pytest_benchmarks_log_${{ env.folder_env }}_${{ env.tag_version }}
          path: |
            pytest_result_${{ env.folder_env }}_${{ env.tag_version }}
            compare_result_${{ env.folder_env }}_${{ env.tag_version }}
            ${{ env.file_json }}
      - name: Download the result on github action
        uses: actions/download-artifact@v3
        with:
          name: pytest_benchmarks_log_${{ env.folder_env }}_${{ env.tag_version }}

      # use github-action-benchmark for graph
      - name: compare result with last version and save on gh-page branch
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Python Benchmark with pytest-benchmark
          tool: 'pytest'
          output-file-path: ${{ env.file_json }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ inputs.save }}
          benchmark-data-dir-path: benchmarks/${{ env.folder_env }}
          alert-threshold: '120%'
          # comment-on-alert: true
          fail-on-alert: true

      - name: Save benchmark report in current branch
        if: inputs.save
        run: |
          git config --global user.name 'benchmark_test'
          git config --global user.email 'benchmark_test@users.noreply.github.com'
          git add ${{ env.file_json }}
          git commit -am "Automated benchmark report"
          git pull
          git push